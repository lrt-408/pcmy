{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设计一个爬虫父类BaseSpyder，包含基本网络连接和html数据获取方法；\n",
    "\n",
    "设计一个子类MySpyder继承BaseSpyder。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "#网络连接\n",
    "import requests\n",
    "#提取内容\n",
    "import re\n",
    "#接口统一\n",
    "from abc import ABC, abstractmethod\n",
    "import time \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义接口 GetNewContent，其中包含 getTiles, getContents, getUrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetNewContent(ABC):\n",
    "    @abstractmethod\n",
    "    def getTitles(self, data):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def getContents(self, data):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def getUrls(self, data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 BaseSpyder 类,包含基本的网络连接和获取 HTML 数据的方法。\n",
    "这个类需要实现 GetNewContent 接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSpyder:\n",
    "    def __init__(self, url, m):\n",
    "        self.header = {\n",
    "            'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36 Edg/118.0.2088.69'\n",
    "        }\n",
    "        self.url = url\n",
    "        self.m = m\n",
    "    #判断能否打开网站\n",
    "    def response(self):\n",
    "        if requests.get(self.url, headers=self.header).status_code == 200:\n",
    "            return requests.get(self.url, headers=self.header)\n",
    "        else :\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 MySpyder 类，它继承了 BaseSpyder 类。需要实现 getContents 方法，获取新闻内容。这里假设新闻内容在特定的 div 中，并且有特定的 class 名称。根据实际情况进行修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySpyder(BaseSpyder,GetNewContent):\n",
    "    def __init__(self, url, m):\n",
    "        #覆盖父类方法：\n",
    "        super().__init__(url, m)\n",
    "\n",
    "    #获取5条新闻标题    \n",
    "    def getTitles(self):\n",
    "        #解决乱码问题\n",
    "        text = self.response().content.decode('utf-8')\n",
    "        if text == False:\n",
    "            print(\"不能成功加载网页\")\n",
    "            return\n",
    "        part = re.compile(r'(?<=<a href=\")info.+?(?=\")')\n",
    "        list1 = part.findall(text)\n",
    "        #print(list1)\n",
    "        cont = 0\n",
    "        for i in list1:\n",
    "            #发送一个HTTP GET请求，获取响应的原始字节内容，并将其解码为Unicode字符\n",
    "            tmp = requests.get(url+'/'+i,headers=self.header).content.decode('utf-8')\n",
    "            #print(tmp)\n",
    "            mytitle = re.compile(r'<b>([\\u4e00-\\u9fa50-9,.，。、“”]+?)</b>')\n",
    "            list2 = mytitle.findall(tmp)\n",
    "            #print(list2)\n",
    "            for j in list2:\n",
    "                print(j)\n",
    "                cont += 1\n",
    "                if cont == 5:\n",
    "                    break\n",
    "            if cont == 5:\n",
    "                break\n",
    "            #print(a2_list)\n",
    "\n",
    "    def getContents(self):\n",
    "        text = self.response().content.decode('utf-8')\n",
    "        if text == False:\n",
    "            print(\"不能成功加载网页\")\n",
    "            return\n",
    "        part = re.compile(r'(?<=<a href=\")info.+?(?=\")')\n",
    "        list1 = part.findall(text)\n",
    "        #print(list1)\n",
    "        cont = 0\n",
    "        for i in list1[:20]:\n",
    "            #发送一个HTTP GET请求，获取响应的原始字节内容，并将其解码为Unicode字符\n",
    "            tmp = requests.get(url+'/'+i,headers=self.header).content.decode('utf-8')\n",
    "            #print(tmp)\n",
    "            mycontents = re.compile(r'<p class=\"vsbcontent_start\" style=\"text-align: left;\">([\\u4e00-\\u9fa5（）0-9《》\\s,.，。、“”]+?)</p>')\n",
    "            list2 = mycontents.findall(tmp)\n",
    "            #print(list2)\n",
    "            for j in list2:\n",
    "                print(j)\n",
    "                cont += 1\n",
    "                if cont == 5:\n",
    "                    break\n",
    "            if cont == 5:\n",
    "                break\n",
    "           \n",
    "\n",
    "    def getUrls(self):\n",
    "        text = self.response().content.decode('utf-8')\n",
    "        if text == False:\n",
    "            print(\"不能成功加载网页\")\n",
    "            return\n",
    "        part = re.compile(r'(?<=<a href=\")info.+?(?=\")')\n",
    "        list1 = part.findall(text)\n",
    "        #print(list1)\n",
    "        cont = 0\n",
    "        for i in list1:\n",
    "            print(url+'/'+i+'/')\n",
    "            cont += 1\n",
    "            if cont == 5:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化：具体网站：https://ybu.edu.cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "（通讯员张宇锋）10月26日下午，农业农村部原副部长、国务院参事室参事于康震在吉林省畜牧业管理局、延边州农业农村局相关负责人的陪同下来我校调研指导工作，校党委书记冯涛、副校长王洪福迎接了于康震一行并陪同调研。\n",
      "（出版社供稿） 10月25日上午，校党委书记冯涛，校党委副书记、校长蔡红星一行到延边大学出版社有限责任公司（以下简称“出版社”）长春分部调研指导工作。\n",
      "（马克思主义学院供稿）10月17日，由吉林省教育厅高校思政处组织的高校马克思主义学院院长论坛在我校举办。吉林省教育厅高校思政处处长杨延秋、吉林省高校网络思想政治工作中心执行主任王佳惠出席论坛。\n",
      "（马克思主义学院供稿）10月13日至17日，全省高校马克思主义学院院长和中小学思政课骨干教师实践研修班在全国高校思想政治理论课教师研修基地（延边大学）（以下简称“延边大学基地”）举办，吉林省教育厅高校思政处处长杨延秋,校党委副书记于金欢出席开班仪式。\n",
      "（通讯员张宇锋）10月26日下午，农业农村部原副部长、国务院参事室参事于康震在吉林省畜牧业管理局、延边州农业农村局相关负责人的陪同下来我校调研指导工作，校党委书记冯涛、副校长王洪福迎接了于康震一行并陪同调研。\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = \"https://ybu.edu.cn\"\n",
    "    m = r'(?<=<a href=\")info.+?(?=\")'\n",
    "    title = MySpyder(url,m)\n",
    "    title.getContents()\n",
    "    #title.getUrls()\n",
    "    #title.getTitles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ybu.edu.cn/info/1020/5867.htm/\n",
      "https://ybu.edu.cn/info/1020/5866.htm/\n",
      "https://ybu.edu.cn/info/1020/5865.htm/\n",
      "https://ybu.edu.cn/info/1020/5864.htm/\n",
      "https://ybu.edu.cn/info/1020/5863.htm/\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = \"https://ybu.edu.cn\"\n",
    "    m = r'(?<=<a href=\")info.+?(?=\")'\n",
    "    title = MySpyder(url,m )\n",
    "    title.getUrls()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
